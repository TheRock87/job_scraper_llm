name: ðŸ¤– AI Job Processing Workflow

permissions:
  contents: write

on:
  # Manual trigger
  workflow_dispatch:
    inputs:
      force_process:
        description: 'Force process all jobs (ignore new jobs only)'
        required: false
        default: false
        type: boolean
  
  # Trigger on schedule (daily at 6 AM UTC)
  schedule:
    - cron: '0 6 * * *'
  
  # Trigger when jobs_raw.csv is updated
  push:
    paths:
      - 'job_filter_app/jobs_raw.csv'
    branches:
      - main

env:
  PYTHON_VERSION: '3.11'

jobs:
  process-jobs:
    runs-on: ubuntu-latest
    
    steps:
    - name: ðŸ“¥ Checkout repository
      uses: actions/checkout@v4
      with:
        fetch-depth: 0  # Full history for job tracking
    
    - name: ðŸ Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: ðŸ“¦ Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install pandas pyyaml requests beautifulsoup4 numpy pydantic markdownify tls-client urllib3 regex
    
    - name: Install your package
      run: pip install -e .
    
    - name: "ðŸ•¸ï¸ Scrape jobs and generate jobs_raw.csv"
      run: python job_filter_app/scraper_only.py
    
    - name: List files for debug
      run: ls -l job_filter_app/
    
    - name: ðŸ” Process and identify new jobs
      id: process-jobs
      working-directory: job_filter_app
      run: python github_actions_workflow.py
      env:
        CSV_FILE: data/jobs_raw.csv
        HISTORY_FILE: data/job_history.json

    
    - name: ðŸ“Š Display processing results
      run: |
        echo "ðŸ“ˆ New jobs found: ${{ steps.process-jobs.outputs.new_jobs_count }}"
        echo "ðŸ“‹ Total jobs: ${{ steps.process-jobs.outputs.total_jobs_count }}"
        echo "ðŸ†• Has new jobs: ${{ steps.process-jobs.outputs.has_new_jobs }}"
    
    - name: ðŸš« Skip if no new jobs (unless forced)
      if: steps.process-jobs.outputs.has_new_jobs != 'true' && github.event.inputs.force_process != 'true'
      run: |
        echo "â­ï¸ No new jobs found, skipping LLM processing"
        exit 0
    
    - name: ðŸ“¤ Upload results as artifacts
      if: steps.process-jobs.outputs.has_new_jobs == 'true' || github.event.inputs.force_process == 'true'
      uses: actions/upload-artifact@v4
      with:
        name: job-processing-results
        path: |
          job_filter_app/data/
          job_filter_app/job_history.json
        retention-days: 30

    - name: ðŸ“Š Create summary comment
      if: steps.process-jobs.outputs.has_new_jobs == 'true' || github.event.inputs.force_process == 'true'
      run: |
        echo "## ðŸ¤– Job Processing Complete" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "- **Total jobs processed:** ${{ steps.process-jobs.outputs.total_jobs_count }}" >> $GITHUB_STEP_SUMMARY
        echo "- **New jobs found:** ${{ steps.process-jobs.outputs.new_jobs_count }}" >> $GITHUB_STEP_SUMMARY
        echo "- **Processing triggered:** ${{ github.event_name }}" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "ðŸ“ **Artifacts available:**" >> $GITHUB_STEP_SUMMARY
        echo "- `data/all_jobs.csv` - All jobs with classifications" >> $GITHUB_STEP_SUMMARY
        echo "- `data/summary.json` - Processing statistics" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "â˜ï¸ **Google Drive:** Files uploaded to AI-Jobs folder" >> $GITHUB_STEP_SUMMARY
    
    - name: ðŸ”„ Commit updated history
      if: steps.process-jobs.outputs.has_new_jobs == 'true' || github.event.inputs.force_process == 'true'
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"
        git add job_filter_app/job_history.json
        git commit -m "ðŸ“Š Update job history - ${{ steps.process-jobs.outputs.new_jobs_count }} new jobs" || echo "No changes to commit"
        git push 
